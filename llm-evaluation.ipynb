{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3c5f220e58fe4b00a5c90e586354446e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99e28040004e415eb84e11c66dff21ef","IPY_MODEL_b50f220d81994420b19171c01dad16b8","IPY_MODEL_7bd31bada0444e5682d74030848810d5"],"layout":"IPY_MODEL_54a8f20375774e81a46856d4aee0c66d"}},"99e28040004e415eb84e11c66dff21ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41624439c34349d8977918f83420a3f2","placeholder":"​","style":"IPY_MODEL_f8bbed179aad45148286cd3a2711bc71","value":"tokenizer_config.json: 100%"}},"b50f220d81994420b19171c01dad16b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_58cde573cba84c0ea0daaf27269699bb","max":51052,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae7ad17ff7074c5b92f88277a5ffbcb0","value":51052}},"7bd31bada0444e5682d74030848810d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f53a1ed397ff4396a7fa6005939a6d37","placeholder":"​","style":"IPY_MODEL_07c7fd60b9a94a23a5ecfd54a79e6466","value":" 51.1k/51.1k [00:00&lt;00:00, 2.27MB/s]"}},"54a8f20375774e81a46856d4aee0c66d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41624439c34349d8977918f83420a3f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8bbed179aad45148286cd3a2711bc71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58cde573cba84c0ea0daaf27269699bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae7ad17ff7074c5b92f88277a5ffbcb0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f53a1ed397ff4396a7fa6005939a6d37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07c7fd60b9a94a23a5ecfd54a79e6466":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2a63fd5853c4181980c732cbc11383c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d8fa7e8a94a45e8bdddc6e5cf12f727","IPY_MODEL_b33f5a89a0014c9aa21b0ec8b46cb086","IPY_MODEL_493ee4eb054a489da8b5212fed975166"],"layout":"IPY_MODEL_f890cbda2fd2435482dafae31f755386"}},"1d8fa7e8a94a45e8bdddc6e5cf12f727":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8b6a73329a84664bb466a2aa7a19e11","placeholder":"​","style":"IPY_MODEL_1d7959f1f1684c06bda0bc89aff58686","value":"tokenizer.json: 100%"}},"b33f5a89a0014c9aa21b0ec8b46cb086":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c62420fe9264c02bb306a0940e4802d","max":9085698,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd92f47eed3541d390648c313a8971d3","value":9085698}},"493ee4eb054a489da8b5212fed975166":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fa4dca566974f1bad3852266a1d91f5","placeholder":"​","style":"IPY_MODEL_77342d45f6314681b03f37f6193ca879","value":" 9.09M/9.09M [00:09&lt;00:00, 998kB/s]"}},"f890cbda2fd2435482dafae31f755386":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8b6a73329a84664bb466a2aa7a19e11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d7959f1f1684c06bda0bc89aff58686":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c62420fe9264c02bb306a0940e4802d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd92f47eed3541d390648c313a8971d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4fa4dca566974f1bad3852266a1d91f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77342d45f6314681b03f37f6193ca879":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17a0c1d5b60e48ecb974b98e5d23692c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8058bb20e2794b2c88ecb4c15570ddad","IPY_MODEL_c652876466964fb3ab0a7e95df5ee910","IPY_MODEL_4a54b102d5744ee582ddc15fbc90c554"],"layout":"IPY_MODEL_cf06731b0eee4e2e8d63b13feea27059"}},"8058bb20e2794b2c88ecb4c15570ddad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6edf610039d49b1922b2a729635ebbd","placeholder":"​","style":"IPY_MODEL_f6047ac3f0614a7c981bdc387774370e","value":"special_tokens_map.json: 100%"}},"c652876466964fb3ab0a7e95df5ee910":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd4759aeff3b49038a1a3f2d58a390ff","max":345,"min":0,"orientation":"horizontal","style":"IPY_MODEL_105d95654a1a4b41946f44ace79b9555","value":345}},"4a54b102d5744ee582ddc15fbc90c554":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc01a1e58db94a098c0bd11d425b90fe","placeholder":"​","style":"IPY_MODEL_00c69d05d9594c74a0394dac19bdb4fd","value":" 345/345 [00:00&lt;00:00, 23.0kB/s]"}},"cf06731b0eee4e2e8d63b13feea27059":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6edf610039d49b1922b2a729635ebbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6047ac3f0614a7c981bdc387774370e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd4759aeff3b49038a1a3f2d58a390ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"105d95654a1a4b41946f44ace79b9555":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cc01a1e58db94a098c0bd11d425b90fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00c69d05d9594c74a0394dac19bdb4fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10199472,"sourceType":"datasetVersion","datasetId":6302498},{"sourceId":10245905,"sourceType":"datasetVersion","datasetId":6336717}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n!pip install peft","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dgZvLgYC9C2D","outputId":"bcf6dde3-7755-4c4f-a054-dd981d26bbbc","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U bitsandbytes\n!pip install torch","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z9jcFixX_qKq","outputId":"eba3239f-c859-4f72-c56f-113c50992317","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_response(model, tokenizer, input_text, isTTM = False):\n    max_length = 512\n    input_ids = tokenizer(input_text, return_tensors=\"pt\")\n    if not isTTM:\n      outputs = model.generate(input_ids['input_ids'], max_new_tokens=2048,temperature = 0.6, do_sample = True, top_k = 50,top_p = 0.95)\n    else:\n      outputs = model.generate(input_ids['input_ids'], max_new_tokens=max_length, num_beams = 2, early_stopping = True)\n    res = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return res","metadata":{"id":"MA2sLab89b0I","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_output(text,max_cot = 1):\n  buffer = []\n  buffer.append(text)\n  for i in range(max_cot):\n    input_text = f\"\"\"\n    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n    Role: You are an Instructions Providing AI that generates tailored steps to solve the given question.\n\n    Instructions:\n    - Carefully analyze the provided question before generating steps.\n    - Only generate **specific steps** that are relevant to solving this particular question.\n    - Avoid using generic or repetitive steps such as \"Identify key information\" or \"Verify the solution\".\n    - Focus on logical reasoning, calculations, or operations that are **directly necessary** to solve the question.\n    - Give Exactly 4 steps.\n    - Do not provide descriptions or explanations for the steps.\n    - Only output the **step titles** relevant to the question at hand.\n    - Follow the provided format:\n      Step 1: [Tailored Step Title According to Question]\n      Step 2: [Tailored Step Title According to Question]\n      Step 3: [Tailored Step Title According to Question]\n      Step 4: [Tailored Step Title According to Question]\n    - Do not generate an answer to the question or hint at the solution.\n    - Do not exceed 4 Steps\n    Generate the steps based solely on the question below.\n    <|eot_id|><|start_header_id|>user<|end_header_id|>\"{text}\"<|eot_id|>\"\"\"\n    internal_thought = generate_response(TTM_model, tokenizer, input_text,isTTM = True)\n    internal_thought = extract_final_answer(internal_thought)\n    internal_thought = f\"Internal_thought{i+1}:\"+\"\\n\"+internal_thought\n    buffer.append(internal_thought)\n    prompt = '\\n'.join(buffer)\n    final_input = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n    Role: You are a highly intelligent AI assistant specializing in mathematics and coding. Your expertise includes solving complex math problems, writing and debugging code, explaining mathematical concepts, and providing optimized solutions for coding challenges. When presented with a question or problem, you will: 1. Analyze the problem carefully. 2. Provide clear and concise explanations for your reasoning. 3. Offer step-by-step solutions for math and coding problems. 4. Generate clean, efficient, and well-commented code for programming tasks. You are expected to be accurate, logical, and detailed in your responses.\n    Instruction:\n    - Use the internal_thought to guide yourself to a correct answer and verify that it is correct before responding to the user.\n    - Final output needs to be an answer for the question.\n    - The last sentence needs to be the correct option for the question.\n    - Provide the index of the correct option\n    - Always provide the correct option number at the end\n    - Follow the strictly the Structure of output:\n        Explanation : Elaborate on steps in internal_thought provided\n        Answer : Correct Answer\n        Option : Correct Option number for the correct answer in the choices\n    - Do not deviate from the format mentioned above\n    - Option can only be any one value in 0,1,2,3 and should only be the option number\n    - Do not hallucinate\n    - Do not deviate from the instructions\n    Example:\n      Question : What is 1 + 2 ?\n      Choices:\n      0) 3\n      1) 1\n      2) 2\n      3) 4\n      Explanation : 1 + 2 adds to 3\n      Answer : the answer is 3\n      Option : 0\n    <|end_header_id|>\n    <|start_header_id|>user<|end_header_id|>\"{prompt}\"<|eot_id|>\"\"\"\n    final_output = generate_response(model_finetuned, tokenizer, final_input)\n    final_output = f\"{i+1}th Output:\\n\" + final_output\n    buffer.append(final_output)\n  return final_output","metadata":{"id":"VZje8dck9MX_","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U peft","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rf1DCLj-BWb4","outputId":"ebd2113d-91b8-49b2-c83c-84358b644fca","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\nmodel_id = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n\ntorch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel_finetuned = AutoModelForCausalLM.from_pretrained(model_id,load_in_4bit=True,torch_dtype = torch.bfloat16).to(torch_device)\nmodel_finetuned.load_adapter('/kaggle/input/main-adapter')\nTTM_id = 'unsloth/Llama-3.2-1B-Instruct-bnb-4bit'\nTTM_model = AutoModelForCausalLM.from_pretrained(TTM_id,load_in_4bit=True,torch_dtype = torch.bfloat16).to(torch_device)\nTTM_model.load_adapter('/kaggle/input/adapter')\ntokenizer = AutoTokenizer.from_pretrained(model_id)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281,"referenced_widgets":["3c5f220e58fe4b00a5c90e586354446e","99e28040004e415eb84e11c66dff21ef","b50f220d81994420b19171c01dad16b8","7bd31bada0444e5682d74030848810d5","54a8f20375774e81a46856d4aee0c66d","41624439c34349d8977918f83420a3f2","f8bbed179aad45148286cd3a2711bc71","58cde573cba84c0ea0daaf27269699bb","ae7ad17ff7074c5b92f88277a5ffbcb0","f53a1ed397ff4396a7fa6005939a6d37","07c7fd60b9a94a23a5ecfd54a79e6466","c2a63fd5853c4181980c732cbc11383c","1d8fa7e8a94a45e8bdddc6e5cf12f727","b33f5a89a0014c9aa21b0ec8b46cb086","493ee4eb054a489da8b5212fed975166","f890cbda2fd2435482dafae31f755386","a8b6a73329a84664bb466a2aa7a19e11","1d7959f1f1684c06bda0bc89aff58686","9c62420fe9264c02bb306a0940e4802d","bd92f47eed3541d390648c313a8971d3","4fa4dca566974f1bad3852266a1d91f5","77342d45f6314681b03f37f6193ca879","17a0c1d5b60e48ecb974b98e5d23692c","8058bb20e2794b2c88ecb4c15570ddad","c652876466964fb3ab0a7e95df5ee910","4a54b102d5744ee582ddc15fbc90c554","cf06731b0eee4e2e8d63b13feea27059","e6edf610039d49b1922b2a729635ebbd","f6047ac3f0614a7c981bdc387774370e","cd4759aeff3b49038a1a3f2d58a390ff","105d95654a1a4b41946f44ace79b9555","cc01a1e58db94a098c0bd11d425b90fe","00c69d05d9594c74a0394dac19bdb4fd"]},"id":"5aLAajjb_BiW","outputId":"8e6f01a5-a0a2-442e-e1e7-b082c90d8aca","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ncolumns = [\n    \"Model Name\",         # Name of the model\n    \"Dataset\",            # Dataset used (e.g., MMLU, GSM8K)\n    \"Task\",               # Specific task or subset of the dataset\n    \"Accuracy\",           # Accuracy metric\n    \"BLEU Score\",         # BLEU score metric\n    \"ROUGE-L Score\",      # ROUGE-L score metric\n]\n\n# Create an empty DataFrame with the specified columns\nevaluation_results = pd.DataFrame(columns=columns)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models = [\"unsloth/llama-3.1-8b-Instruct-bnb-4bit\",\"mistralai/Mistral-7B\",\"gemma2-9b\", \"qwen/Qwen-2-7B\"]\n#temp_model = AutoModelForCausalLM.from_pretrained(models[0],load_in_4bit=True,torch_dtype = torch.bfloat16).to(torch_device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install datasets\n!pip install rouge-score\n!pip install nltk","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5CEyl8RkNwgR","outputId":"bad8d1af-1bb1-411f-8f5d-69cdea296407","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TTM_model.eval()\nmodel_finetuned.eval()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGtbzDcyCh7s","outputId":"5378b537-526f-4886-a1ba-3a584e5312bf","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_final_answer(output: str) -> str:\n    # Assuming \"Assistant:\" precedes the answer\n    if \"assistant\" in output:\n        temp = output.split(\"assistant\")[-1].strip()\n        res = temp.replace('assistant','')\n        return res\n    return output.strip()","metadata":{"id":"4Cn4ovKREih1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"id":"2kWWpFXKIHly","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nfrom rouge_score import rouge_scorer\nfrom nltk.translate.bleu_score import sentence_bleu\n\n\ndef evaluate_mmlu(name):\n    print(\"Evaluating on MMLU...\")\n\n    # Load MMLU dataset (example subset: 'high_school_mathematics')\n    dataset = load_dataset(\"cais/mmlu\", name, split=\"test\")\n\n    rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n    bleu_scores = []\n    rouge_scores = []\n    correct = 0\n    total = 0\n\n    for sample in tqdm(dataset, desc=\"Processing MMLU\", total=len(dataset)):\n        question = sample['question']\n        choices = sample['choices']  # List of options (A, B, C, D)\n        answer = sample['answer']  # Correct choice index\n        ground_truth = choices[answer]\n\n        # Create the input to the LLM (formatted question)\n        temp = '\\n'\n        for n,c in enumerate(choices):\n          temp += f'{n}) {c}\\n'\n        input_text = f\"Question: {question}\\nChoices: {temp}\"\n\n        # Generate response\n        output = generate_output(input_text).strip()\n        number = extract_answer_number(output)\n        rouge_score = rouge.score(ground_truth, output)['rougeL'].fmeasure\n        bleu_score = sentence_bleu([ground_truth.split()], output.split())\n        for i in range(len(output),len(ground_truth)):\n          if i + len(ground_truth) <= len(output):\n            rouge_score = max(rouge_score,rouge.score(ground_truth, output[i:i + len(ground_truth)])['rougeL'].fmeasure)\n            bleu_score = max(rouge_score,sentence_bleu([ground_truth.split()], output[i:i + len(ground_truth)].split()))\n        rouge_scores.append(rouge_score)\n        bleu_scores.append(bleu_score)\n\n        # Match output with options\n        print(f'answer:{answer} generated:{number}')\n        if answer == number:\n          correct += 1\n\n        total += 1\n\n    accuracy = correct / total\n    average_bleu = sum(bleu_scores) / total\n    average_rouge = sum(rouge_scores) / total\n    print(f\"MMLU Accuracy: {accuracy:.4f} ({correct}/{total})\")\n    print(f\"MMLU Average BLEU Score: {average_bleu:.4f}\")\n    print(f\"MMLU Average ROUGE-L Score: {average_rouge:.4f}\")\n    return accuracy, average_bleu, average_rouge\n\ndef evaluate_gsm8k():\n    print(\"Evaluating on GSM8K...\")\n\n    # Load GSM8K dataset\n    dataset = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n\n    rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n    bleu_scores = []\n    rouge_scores = []\n    correct = 0\n    total = 0\n\n    for sample in tqdm(dataset, desc=\"Processing GSM8K\", total=len(dataset)):\n        question = sample['question']\n        ground_truth = sample['answer']  # Ground truth answer as string\n\n        # Generate response\n        input_text = f\"Question: {question}\\nAnswer:\"\n        output = generate_output(input_text).strip()\n\n        # Calculate ROUGE and BLEU\n        rouge_score = rouge.score(ground_truth, output)['rougeL'].fmeasure\n        bleu_score = sentence_bleu([ground_truth.split()], output.split())\n        rouge_scores.append(rouge_score)\n        bleu_scores.append(bleu_score)\n\n    average_bleu = sum(bleu_scores) / total\n    average_rouge = sum(rouge_scores) / total\n    print(f\"GSM8K Average BLEU Score: {average_bleu:.4f}\")\n    print(f\"GSM8K Average ROUGE-L Score: {average_rouge:.4f}\")\n    return accuracy, average_bleu, average_rouge\n\n\ndef extract_answer_number(text):\n    \"\"\"Extract the last number from the model's text output.\"\"\"\n    matches = re.findall(r\"[-+]?\\d*\\.?\\d+\", text)  # Find all integers or decimals\n    if matches:\n        print(int(round(float(matches[-1]))))\n        return int(round(float(matches[-1])))# Return the last number as an integer\n    return None\n\nif __name__ == \"__main__\":\n    # Run evaluations\n    mmlu_m_acc,mmlu_m_bleu,mmlu_m_rouge = evaluate_mmlu(\"college_mathematics\")\n    mmlu_cs_acc,mmlu_cs_bleu,mmlu_cs_rouge = evaluate_mmlu(\"college_computer_science\")\n    # gsm_bleu,gsm_rouge = evaluate_gsm8k()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nz8BNhDANYWG","outputId":"7804de04-8676-4ab6-bcc3-04277a4d2b1e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example of adding a row to the DataFrame\nevaluation_results.loc[len(evaluation_results)] = [\"Llama-3.1-8B-Finetuned-COT\",\"MMLU\",\"College Mathematics\",mmlu_m_acc,mmlu_m_bleu,mmlu_m_rouge]\n\nevaluation_results.loc[len(evaluation_results)] = [\"Llama-3.1-8B-Finetuned-COT\",\"MMLU\",\"College Computer Science\", mmlu_cs_acc, mmlu_cs_bleu,mmlu_cs_rouge]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluation_results.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"dataset = load_dataset(\"cais/mmlu\", 'college_mathematics', split=\"test\")\ndataset[4]","metadata":{"execution":{"iopub.status.busy":"2024-12-19T13:13:44.224401Z","iopub.execute_input":"2024-12-19T13:13:44.225204Z","iopub.status.idle":"2024-12-19T13:13:46.263846Z","shell.execute_reply.started":"2024-12-19T13:13:44.225166Z","shell.execute_reply":"2024-12-19T13:13:46.262991Z"}}},{"cell_type":"markdown","source":"question = dataset[4]['question']\nchoices = dataset[4]['choices']\ntemp = '\\n'\nfor n,c in enumerate(choices):\n    temp += f'{n}) {c}\\n'\ntext = f\"Question: {question}\\nChoices: {temp}\"\n\nres = generate_output(text)\nprint(res)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ff2xwaz_n1h","outputId":"580e7b3c-9c62-4041-80bd-19fee9c8855a","execution":{"iopub.status.busy":"2024-12-19T13:25:38.855071Z","iopub.execute_input":"2024-12-19T13:25:38.855801Z","iopub.status.idle":"2024-12-19T13:26:55.535329Z","shell.execute_reply.started":"2024-12-19T13:25:38.855761Z","shell.execute_reply":"2024-12-19T13:26:55.534444Z"}}},{"cell_type":"code","source":"def base_model_output(model, text):\n  final_input = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n    Role: You are a highly intelligent AI assistant specializing in mathematics and coding. Your expertise includes solving complex math problems, writing and debugging code, explaining mathematical concepts, and providing optimized solutions for coding challenges. When presented with a question or problem, you will: 1. Analyze the problem carefully. 2. Provide clear and concise explanations for your reasoning. 3. Offer step-by-step solutions for math and coding problems. 4. Generate clean, efficient, and well-commented code for programming tasks. You are expected to be accurate, logical, and detailed in your responses.\n    Instruction:\n    - Final output needs to be an answer for the question.\n    - The last sentence needs to be the correct option for the question.\n    - Provide the index of the correct option\n    - Always provide the correct option number at the end\n    - Follow the strictly the Structure of output:\n        Explanation : Elaborate on steps\n        Answer : Correct Answer\n        Option : Correct Option number for the correct answer in the choices\n    - Do not deviate from the format mentioned above\n    - Option can only be any one value in 0,1,2,3 and should only be the option number\n    - Do not hallucinate\n    - Do not deviate from the instructions\n    Example:\n      Question : What is 1 + 2 ?\n      Choices:\n      0) 3\n      1) 1\n      2) 2\n      3) 4\n      Explanation : 1 + 2 adds to 3\n      Answer : the answer is 3\n      Option : 0\n    <|end_header_id|>\n    <|start_header_id|>user<|end_header_id|>\"{text}\"<|eot_id|>\"\"\"\n\n  return extract_final_answer(generate_response(model, tokenizer, final_input))","metadata":{"id":"41-AL4nzZkrQ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nfrom rouge_score import rouge_scorer\nfrom nltk.translate.bleu_score import sentence_bleu\n\n\ndef evaluate_mmlu(name):\n    print(\"Evaluating on MMLU...\")\n\n    # Load MMLU dataset (example subset: 'high_school_mathematics')\n    dataset = load_dataset(\"cais/mmlu\", name, split=\"test\")\n\n    rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n    bleu_scores = []\n    rouge_scores = []\n    correct = 0\n    total = 0\n\n    for sample in tqdm(dataset, desc=\"Processing MMLU\", total=len(dataset)):\n        question = sample['question']\n        choices = sample['choices']  # List of options (A, B, C, D)\n        answer = sample['answer']  # Correct choice index\n        ground_truth = choices[answer]\n\n        # Create the input to the LLM (formatted question)\n        temp = '\\n'\n        for n,c in enumerate(choices):\n          temp += f'{n}) {c}\\n'\n        input_text = f\"Question: {question}\\nChoices: {temp}\"\n\n        # Generate response\n        output = base_model_output(model_finetuned,input_text).strip()\n        number = extract_answer_number(output)\n        rouge_score = rouge.score(ground_truth, output)['rougeL'].fmeasure\n        bleu_score = sentence_bleu([ground_truth.split()], output.split())\n        for i in range(len(output),len(ground_truth)):\n          if i + len(ground_truth) <= len(output):\n            rouge_score = max(rouge_score,rouge.score(ground_truth, output[i:i + len(ground_truth)])['rougeL'].fmeasure)\n            bleu_score = max(rouge_score,sentence_bleu([ground_truth.split()], output[i:i + len(ground_truth)].split()))\n        rouge_scores.append(rouge_score)\n        bleu_scores.append(bleu_score)\n\n        # Match output with options\n        print(f'answer:{answer} generated:{number}')\n        if answer == number:\n          correct += 1\n\n        total += 1\n\n    accuracy = correct / total\n    average_bleu = sum(bleu_scores) / total\n    average_rouge = sum(rouge_scores) / total\n    print(f\"MMLU Accuracy: {accuracy:.4f} ({correct}/{total})\")\n    print(f\"MMLU Average BLEU Score: {average_bleu:.4f}\")\n    print(f\"MMLU Average ROUGE-L Score: {average_rouge:.4f}\")\n    return accuracy, average_bleu, average_rouge\n\ndef evaluate_gsm8k():\n    print(\"Evaluating on GSM8K...\")\n\n    # Load GSM8K dataset\n    dataset = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n\n    rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n    bleu_scores = []\n    rouge_scores = []\n    correct = 0\n    total = 0\n\n    for sample in tqdm(dataset, desc=\"Processing GSM8K\", total=len(dataset)):\n        question = sample['question']\n        ground_truth = sample['answer']  # Ground truth answer as string\n\n        # Generate response\n        input_text = f\"Question: {question}\\nAnswer:\"\n        output = base_model_output(model_finetuned,input_text).strip()\n\n        # Calculate ROUGE and BLEU\n        rouge_score = rouge.score(ground_truth, output)['rougeL'].fmeasure\n        bleu_score = sentence_bleu([ground_truth.split()], output.split())\n        rouge_scores.append(rouge_score)\n        bleu_scores.append(bleu_score)\n\n    average_bleu = sum(bleu_scores) / total\n    average_rouge = sum(rouge_scores) / total\n    print(f\"GSM8K Average BLEU Score: {average_bleu:.4f}\")\n    print(f\"GSM8K Average ROUGE-L Score: {average_rouge:.4f}\")\n    return accuracy, average_bleu, average_rouge\n\ndef extract_answer_number(text):\n    \"\"\"Extract the last number from the model's text output.\"\"\"\n    matches = re.findall(r\"[-+]?\\d*\\.?\\d+\", text)  # Find all integers or decimals\n    if matches:\n        return int(round(float(matches[-1])))  # Return the last number as an integer\n    return None\n\nif __name__ == \"__main__\":\n    # Run evaluations\n    mmlu_m_acc2,mmlu_m_bleu2,mmlu_m_rouge2 = evaluate_mmlu(\"college_mathematics\")\n    mmlu_cs_acc2,mmlu_cs_bleu2,mmlu_cs_rouge2 = evaluate_mmlu(\"college_computer_science\")\n    # gsm_bleu2,gsm_rouge2 = evaluate_gsm8k()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6TmkNcE3jBB3","outputId":"5ce0961f-6a28-4eaf-a88f-0ba6cad114d9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example of adding a row to the DataFrame\nevaluation_results.loc[len(evaluation_results)] = [\"Llama-3.1-8B-Finetuned\",\"MMLU\",\"College Mathematics\",mmlu_m_acc2,mmlu_m_bleu2,mmlu_m_rouge2]\n\nevaluation_results.loc[len(evaluation_results)] = [\"Llama-3.1-8B-Finetuned\",\"MMLU\",\"College Computer Science\", mmlu_cs_acc2, mmlu_cs_bleu2,mmlu_cs_rouge2]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluation_results.to_csv('evaluations.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Data from evaluation (base and fine-tuned)\nmetrics = ['Accuracy', 'BLEU', 'ROUGE']\ncollege_math_base = [0.26, 0.1298, 0.0313]\ncollege_math_finetuned = [0.37, 0.115865, 0.013732]\n\n# Create bar chart\nx = np.arange(len(metrics))  # Positions for the metrics\nwidth = 0.35  # Bar width\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 5))\n\n# College Mathematics\nax[0].bar(x - width/2, college_math_base, width, label='Base Model', color='skyblue')\nax[0].bar(x + width/2, college_math_finetuned, width, label='Fine-tuned Model', color='orange')\nax[0].set_title('College Mathematics')\nax[0].set_xticks(x)\nax[0].set_xticklabels(metrics)\nax[0].set_ylabel('Scores')\nax[0].legend()\n\n# College Computer Science\nax[1].bar(x - width/2, college_cs_base, width, label='Base Model', color='skyblue')\nax[1].bar(x + width/2, college_cs_finetuned, width, label='Fine-tuned Model', color='orange')\nax[1].set_title('College Computer Science')\nax[1].set_xticks(x)\nax[1].set_xticklabels(metrics)\nax[1].set_ylabel('Scores')\nax[1].legend()\n\n# Adjust layout and show plot\nplt.tight_layout()\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"id":"dC9E-loPvmBa","outputId":"76c904fb-b5ca-4965-977d-864bd65edb1f","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig.savefig('comparision1')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}